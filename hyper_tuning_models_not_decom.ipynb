{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aplicação de Hypertuning aos modelos de machine learning \n",
    "* Este código de previsão Multi-step aplica diferentes métodos de hypertuning aos modelos MLP, LSTM, Árvore de Decisão e Random Forest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importação de bibliotecas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import tensorflow as tf\n",
    "import math\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, LSTM, Conv1D, MaxPooling1D,  Bidirectional, Flatten \n",
    "from sklearn.model_selection import cross_val_score\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn import linear_model\n",
    "import time\n",
    "from sklearn.model_selection import RandomizedSearchCV, KFold\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lista de arquivos que estão na pasta indicada como raiz \n",
    "* O comando os.listdir retorna uma lista com o nome de todos os arquivos contidos na pasta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = r'C:\\Users\\eluar\\Documents\\Estudo_IA_Python\\Artigo_Previ_Dados_MET\\BASE_DADOS_MET'\n",
    "arquivos = os.listdir(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Montar janelas para previsão Multi-Step\n",
    "* Esta função recebe um conjunto de dados e monta as janelas de previsão juntamente com os steps a serem previstos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def montarJanela(data, janela, step):\n",
    "    \n",
    "    x, y = [],[]\n",
    "    \n",
    "    for i in range(janela, len(data)):\n",
    "        \n",
    "        fim_y = i+step\n",
    "        if fim_y > len(data):\n",
    "            break\n",
    "        \n",
    "        x.append(data[i-janela:i,0])\n",
    "        y.append(data[i:fim_y,0])\n",
    "        \n",
    "    return np.array(x), np.array(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cria as variáveis que definem o número de entradas e saídas das RNAs \n",
    "* TM_janela é a variável utilizada para determinar o número de entradas das RNAS (Janela de previsão)\n",
    "* TM_step é a variável utilizada para determinar o número de saídas das RNAS (Passos a frete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TM_janela = 0\n",
    "TM_step = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Função para criar uma RNA CNN-LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def criarRedeLSTM(optimizer, activation1, activation2, neurons1, neurons2, neurons3):\n",
    "    Regressor = Sequential()\n",
    "    Regressor.add(Conv1D(filters = 128, kernel_size = 2, activation = activation1, input_shape=(TM_janela, 1)))\n",
    "    Regressor.add(MaxPooling1D(pool_size = 1))\n",
    "    Regressor.add(LSTM(units = neurons1, return_sequences = True, activation = 'tanh'))\n",
    "    Regressor.add(Dropout(0.2))\n",
    "    Regressor.add(LSTM(units = neurons2, activation = 'tanh'))\n",
    "    Regressor.add(Dropout(0.2))\n",
    "    Regressor.add(Dense(units = neurons3, activation = activation2))\n",
    "    Regressor.add(Dropout(0.1))\n",
    "    Regressor.add(Dense(TM_step, activation = 'linear'))\n",
    "    \n",
    "    Regressor.compile(loss= 'mean_squared_error', optimizer= optimizer, metrics=['mean_absolute_error'])\n",
    "    return Regressor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelos Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def criarLSTMRD(x_train, y_train, janela, step, local_arquivo):\n",
    "    \n",
    "    #Altera a entrada para um formato compativél com a as entradas da RNA LSTM \n",
    "    #x_train = x_train.reshape((x_train.shape[0], x_train.shape[1], 1))\n",
    "    \n",
    "    x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 1))   \n",
    "    \n",
    "    print(np.shape(x_train))\n",
    "    print(np.shape(y_train))\n",
    "    \n",
    "    start = time.time() #Tempo inicial\n",
    "    SEED = 10\n",
    "    np.random.seed(SEED)\n",
    "    \n",
    "    regressor = KerasRegressor(build_fn= criarRedeLSTM)\n",
    "    \n",
    "    parameters = {'batch_size':[128, 256, 512],\n",
    "                  'optimizer':['adam', 'sgd', 'RMSprop'],\n",
    "                  'activation1':['linear','relu','elu','tanh', 'sigmoid'],\n",
    "                  'activation2':['linear','relu','elu','tanh', 'sigmoid'],\n",
    "                  'neurons1':[400, 200],\n",
    "                  'neurons2':[100, 50], \n",
    "                  'neurons3':[50, 25]\n",
    "                 }\n",
    "    buscaLSTM = RandomizedSearchCV(regressor, \n",
    "                                   parameters,\n",
    "                                   n_iter = 10,\n",
    "                                   scoring='r2',\n",
    "                                   return_train_score=True,\n",
    "                                   cv = KFold(n_splits = 5, shuffle = True),\n",
    "                                   random_state = SEED\n",
    "                                  )\n",
    "    \n",
    "    buscaLSTM = buscaLSTM.fit(x_train, y_train, epochs = 400, verbose = 0)\n",
    "    end = time.time() #Tempo final \n",
    "    tempo = round(end-start, 4) #calcula o tempo de execução do modelo\n",
    "   \n",
    "    # Pega os melhores parametros \n",
    "    melhores_parametros = buscaLSTM.best_params_\n",
    "    melhor_precisao = buscaLSTM.best_score_ # Verificar Scores dos modelos \n",
    "\n",
    "    print(\"----------//------Resultados LSTM RD--------//-----------\")\n",
    "    print(\"O tempo de execução LSTM: \", tempo)\n",
    "    print(melhores_parametros)\n",
    "    print(melhor_precisao)\n",
    "    print(\"----------//-----------------------------------------//-----------\")\n",
    "    \n",
    "    #Criar o arquivo de texto no diretório para salvar as informações de configuração do modelo\n",
    "    titulo = \"----------//------Resultados LSTM Random Search--------//-----------\"\n",
    "    final = \"----------//-------------------------------------------//------------\"\n",
    "    with open('LSTM_RD_SEARCH.txt', 'a') as arquivo:\n",
    "        arquivo.write(f'{titulo}\\nLocalidade_municipio: {local_arquivo}\\nJanela: {janela}\\nStep: {step}\\nTempo:{tempo}\\nMelhores Parametros: {melhores_parametros}\\nPrecisao r2: {melhor_precisao}\\n{final}\\n')\n",
    "\n",
    "        \n",
    "    \n",
    "def criarRDForestRD(x_train, y_train, janela, step, local_arquivo): \n",
    "    \n",
    "    start = time.time() #Tempo inicial\n",
    "    SEED = 10\n",
    "    np.random.seed(SEED)\n",
    "\n",
    "    \"\"\"\n",
    "       Esses parâmetros servem para restringir a liberdade da árvore a fim de evitar o sobreajuste\n",
    "       max_depth =  profundidade maxima da árvore\n",
    "       min_samples_split = número mínimo de amostras que um nó deve ter antes que possa ser dividido\n",
    "       min_samples_leaf = número mínimo de amostras que um nó da folha deve ter \n",
    "       max_leaf_nodes = número máximo de nós da folha \n",
    "    \"\"\"\n",
    "    parameters = {'n_estimators':[10, 20, 30, 40, 50, 60, 70, 80],\n",
    "                  'max_depth':[3, 6, 9, 12, 15, 18, 21, 24],\n",
    "                  'min_samples_split':[16, 32, 64, 128, 256, 512],\n",
    "                  'min_samples_leaf':[16, 32, 64, 128, 256, 512], \n",
    "                  'max_leaf_nodes':[12, 24, 36, 48, 60, 72, 84, 96]\n",
    "                 }\n",
    "    \n",
    "    buscaRF = RandomizedSearchCV(RandomForestRegressor(), \n",
    "                                 parameters,\n",
    "                                 n_iter = 200,\n",
    "                                 scoring='r2',\n",
    "                                 return_train_score=True,\n",
    "                                 cv = KFold(n_splits = 5, shuffle = True),\n",
    "                                 random_state = SEED\n",
    "                                )\n",
    "    \n",
    "    buscaRF = buscaRF.fit(x_train, y_train)\n",
    "    end = time.time() #Tempo final \n",
    "    tempo = round(end-start, 4) #calcula o tempo de execução do modelo\n",
    "   \n",
    "    # Pega os melhores parametros \n",
    "    melhores_parametros = buscaRF.best_params_\n",
    "    melhor_precisao = buscaRF.best_score_\n",
    "\n",
    "    print(\"----------//------Resultados Random Forest RD--------//-----------\")\n",
    "    print(\"O tempo de execução random forest e: \", tempo)\n",
    "    print(melhores_parametros)\n",
    "    print(melhor_precisao)\n",
    "    print(\"----------//-----------------------------------------//-----------\")\n",
    "    \n",
    "    #Criar o arquivo de texto no diretório para salvar as informações de configuração do modelo\n",
    "    titulo = \"----------//------Resultados Random Forest Random Search--------//-----------\"\n",
    "    final = \"----------//----------------------------------------------------//------------\"\n",
    "    with open('RD_FOREST_RD_SEARCH.txt', 'a') as arquivo:\n",
    "        arquivo.write(f'{titulo}\\nLocalidade_municipio: {local_arquivo}\\nJanela: {janela}\\nStep: {step}\\nTempo:{tempo}\\nMelhores Parametros: {melhores_parametros}\\nPrecisao r2: {melhor_precisao}\\n{final}\\n')\n",
    "    \n",
    "\n",
    "def criarArvoreRD(x_train, y_train, janela, step, local_arquivo):\n",
    "    \n",
    "    start = time.time()# Tempo inicial\n",
    "    SEED = 10\n",
    "    np.random.seed(SEED)\n",
    "    \n",
    "    \"\"\"\n",
    "       Esses parâmetros servem para restringir a liberdade da árvore a fim de evitar o sobreajuste\n",
    "       max_depth =  profundidade maxima da árvore\n",
    "       min_samples_split = número mínimo de amostras que um nó deve ter antes que possa ser dividido\n",
    "       min_samples_leaf = número mínimo de amostras que um nó da folha deve ter \n",
    "       max_leaf_nodes = número máximo de nós da folha \n",
    "    \"\"\"\n",
    "    parameters = {'max_depth':[3, 6, 9, 12, 15, 18, 21, 24],\n",
    "                  'min_samples_split':[32, 64, 128, 256, 512],\n",
    "                  'min_samples_leaf':[32, 64, 128, 256, 512], \n",
    "                  'max_leaf_nodes':[12, 24, 36, 48, 60, 72, 84, 96]\n",
    "                 }\n",
    "    \n",
    "    buscaRD = RandomizedSearchCV(DecisionTreeRegressor(), \n",
    "                                 parameters,\n",
    "                                 n_iter = 200,\n",
    "                                 scoring='r2',\n",
    "                                 return_train_score=True,\n",
    "                                 cv = KFold(n_splits = 5, shuffle = True),\n",
    "                                 random_state = SEED\n",
    "                                )\n",
    "    \n",
    "    buscaRD = buscaRD.fit(x_train, y_train)\n",
    "    end = time.time() #Tempo final \n",
    "    tempo = round(end-start, 4) #calcula o tempo de execução do modelo\n",
    "   \n",
    "    # Pega os melhores parametros \n",
    "    melhores_parametros = buscaRD.best_params_\n",
    "    melhor_precisao = buscaRD.best_score_\n",
    "\n",
    "    print(\"----------//------Resultados Arvore de decisão RD--------//-----------\")\n",
    "    print(\"O tempo de execução da Arvore e: \", tempo)\n",
    "    print(melhores_parametros)\n",
    "    print(melhor_precisao)\n",
    "    print(\"----------//-----------------------------------------//-----------\")\n",
    "    \n",
    "    #Criar o arquivo de texto no diretório para salvar as informações de configuração do modelo\n",
    "    titulo = \"----------//------Resultados Arvore Decisao Random Search--------//-----------\"\n",
    "    final = \"----------//-----------------------------------------------------//------------\"\n",
    "    with open('ARVORE_DECISAO_RD_SEARCH.txt', 'a') as arquivo:\n",
    "        arquivo.write(f'{titulo}\\nLocalidade_municipio: {local_arquivo}\\nJanela: {janela}\\nStep: {step}\\nTempo:{tempo}\\nMelhores Parametros: {melhores_parametros}\\nPrecisao r2: {melhor_precisao}\\n{final}\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abre os arquivos, normaliza e aplica os modelos  com dierentes janelas de previsão "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cont = 0 \n",
    "while (cont < len(arquivos)):\n",
    "    \n",
    "    #Monta o caminho com um arquivo específico \n",
    "    caminho = r\"\"+file+\"\\\\\"+arquivos[cont]\n",
    "    \n",
    "    #Abre o arquivo na pasta \n",
    "    df = pd.read_excel(caminho)\n",
    "    #display(df)\n",
    "    \n",
    "    #atribui os dados a variável DTF\n",
    "    DTF = df[['PRECIPITACAO(mm) (ACM)']]\n",
    "    #VENTO_VEL_H (m/s) (MD)  PRECIPITACAO(mm) (ACM) UMID_REL_AR_H (%) (MD) TEMPMED (C) (MD)\n",
    "    \n",
    "    # Muda a escala dos valores para 0 a 1\n",
    "    scaler = MinMaxScaler()\n",
    "    dataF = scaler.fit_transform(DTF)\n",
    "    \n",
    "    \n",
    "    #define o tamanho das janelas e o número de passos a frente para previsão \n",
    "    janelas = [3]\n",
    "    steps = [1, 2, 3, 4]\n",
    "    \n",
    "    for i in janelas:\n",
    "        for j in steps:\n",
    "            x, y = montarJanela(dataF, i, j)\n",
    "            print(f\"Tamanho Janela x QTD Step: {i} x {j} \")\n",
    "            \n",
    "            #Parametros necessários para execução da MLP TM_janela, TM_step\n",
    "            global TM_janela, TM_step\n",
    "            TM_janela = i \n",
    "            TM_step = j\n",
    "            #---------------------------//--------------//---------------------\n",
    "            #criarLSTMRD(x, y, i, j, arquivos[cont])\n",
    "            criarRDForestRD(np.array(x), np.array(y), i, j, arquivos[cont])\n",
    "            #criarArvoreRD(x, y, i, j, arquivos[cont])\n",
    "    cont = cont+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
